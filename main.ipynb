{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomo9\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\tomo9\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\neptune\\internal\\backends\\hosted_client.py:48: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
      "  from neptune.version import version as neptune_client_version\n",
      "C:\\Users\\tomo9\\AppData\\Local\\Temp\\ipykernel_23048\\1713090962.py:23: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/NTLAB/HypnoGAN/e/HYPNOG-64\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# Local packages:\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "# 3rd party packages:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm,trange\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilenames\n",
    "import ast \n",
    "import matplotlib.pyplot as plt\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import neptune\n",
    "from neptune.types import File\n",
    "run = neptune.init_run(\n",
    "    project=\"NTLAB/HypnoGAN\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJhNGRjNDgzOC04OTk5LTQ0YTktYjQ4Ny1hMTE4NzRjNjBiM2EifQ==\",\n",
    ")\n",
    "\n",
    "\n",
    "# personal packages:\n",
    "#from Data.preprocess import preprocess_data\n",
    "#from model.timegan import TimeGAN\n",
    "#from model.utils import timegan_trainer, timegan_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeGAN_Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A time series dataset for TimeGAN.\n",
    "    Args:\n",
    "        data(numpy.ndarray): the padded dataset to be fitted. Has to transform to ndarray from DataFrame during initialize\n",
    "        time(numpy.ndarray): the length of each data\n",
    "    Parameters:\n",
    "        - x (torch.FloatTensor): the real value features of the data\n",
    "        - t (torch.LongTensor): the temporal feature of the data\n",
    "    \"\"\"\n",
    "    def __init__(self,data, time=None):\n",
    "        #sanity check data and time\n",
    "        \n",
    "        \n",
    "        \n",
    "        if isinstance(time,type(None)):\n",
    "            time = [len(x) for x in data]\n",
    "            \n",
    "        if len(data) != len(time):\n",
    "            run.stop()\n",
    "            raise ValueError( f\"len(data) `{len(data)}` != len(time) {len(time)}\")\n",
    "            \n",
    "        \n",
    "        self.X = torch.FloatTensor(data)\n",
    "        self.T = torch.LongTensor(time)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx],self.T[idx]\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Minibatch sampling\n",
    "        \"\"\"\n",
    "        # Pad sequences to max length\n",
    "        X_mb = [X for X in batch[0]]\n",
    "        \n",
    "        # The actual length of each data\n",
    "        T_mb = [T for T in batch[1]]\n",
    "        \n",
    "        return X_mb, T_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    The embedding network (encoder) that maps the input data to a latent space.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim, hidden_dim, num_layers, padding_value=0, max_seq_len=1000):\n",
    "        super(EmbeddingNetwork, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.padding_value = padding_value\n",
    "        self. max_seq_len = max_seq_len\n",
    "\n",
    "        #Embedder Architecture\n",
    "        self.emb_rnn = nn.GRU(\n",
    "            input_size=self.feature_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.emb_linear = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.emb_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        # Init weights\n",
    "        # Default weights of TensorFlow is Xavier Uniform for W and 1 or 0 for b\n",
    "        # Reference: \n",
    "        # - https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable\n",
    "        # - https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py#L484-L61\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.emb_rnn.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(param.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    param.data.fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    param.data.fill_(1)\n",
    "\n",
    "            for name, param in self.emb_linear.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif 'bias' in name:\n",
    "                    param.data.fill_(0)\n",
    "    def forward(self,X,T):\n",
    "        \"\"\"Forward pass of the embedding features from original space to latent space.\n",
    "        Args:\n",
    "            X: Input time series feature (B x S x F)\n",
    "            T: INput temporal information (B)\n",
    "        Returns:\n",
    "            H: latent space embeddings (B x S x H)\n",
    "        \"\"\"\n",
    "        # Dynamic RNN input for ignoring paddings\n",
    "\n",
    "        X_pack = nn.utils.rnn.pack_padded_sequence(\n",
    "            input =X,\n",
    "            lengths=T,\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False,\n",
    "        )\n",
    "\n",
    "        # 128*100*71\n",
    "        H_o,H_t = self.emb_rnn(X_pack)\n",
    "\n",
    "        #pad RNN output back to sequence length\n",
    "\n",
    "        H_o,T = nn.utils.rnn.pad_packed_sequence(\n",
    "            sequence=H_o,\n",
    "            batch_first=True,\n",
    "            padding_value=self.padding_value,\n",
    "            total_length=self.max_seq_len,\n",
    "        )\n",
    "\n",
    "        #128*100*10\n",
    "        logits = self.emb_linear(H_o)\n",
    "        H = self.emb_sigmoid(logits)\n",
    "\n",
    "        return H\n",
    "    \n",
    "class RecoveryNetwork(nn.Module):\n",
    "    \"\"\"The recovery network (decoder) for TimeGAN\n",
    "    \"\"\"\n",
    "    def __init__(self,hidden_dim,feature_dim,num_layers,padding_value=0,max_seq_len=1000):\n",
    "        super(RecoveryNetwork, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.padding_value = padding_value\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        #Recovery Architecture\n",
    "        self.rec_rnn = nn.GRU(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.rec_linear = nn.Linear(self.hidden_dim, self.feature_dim)\n",
    "\n",
    "        # Init weights\n",
    "        # Default weights of TensorFlow is Xavier Uniform for W and 1 or 0 for b\n",
    "        # Reference: \n",
    "        # - https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable\n",
    "        # - https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py#L484-L614\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for name,param in self.rec_rnn.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.xavier_uniform_(param.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    param.data.fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    param.data.fill_(0)\n",
    "            for name,param in self.rec_linear.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif 'bias' in name:\n",
    "                    param.data.fill_(0)\n",
    "        \n",
    "    def forward(self,H,T):\n",
    "        \"\"\" Forward pass of the recovery features from latent space to original space.\n",
    "        Args:\n",
    "            H: latent representation (B x S x E)\n",
    "            T: input temporal information (B)\n",
    "        Returns:\n",
    "            X_tilde: recovered features (B x S x F)\n",
    "        \"\"\"\n",
    "        #Dynamic RNN input for ignoring paddings\n",
    "        H_pack = nn.utils.rnn.pack_padded_sequence(\n",
    "            input = H,\n",
    "            lengths=T,\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False,\n",
    "        )\n",
    "        #128 x 100 x 10\n",
    "        H_o,H_t = self.rec_rnn(H_pack)\n",
    "        #pad RNN output back to sequence length\n",
    "        H_o,T = nn.utils.rnn.pad_packed_sequence(\n",
    "            sequence=H_o,\n",
    "            batch_first=True,\n",
    "            padding_value=self.padding_value,\n",
    "            total_length=self.max_seq_len,\n",
    "        )\n",
    "        #128 x 100 x 71\n",
    "        X_tilde = self.rec_linear(H_o)\n",
    "        return X_tilde\n",
    "\n",
    "class SupervisorNetwork(nn.Module):\n",
    "        \"\"\"The supervisor network for TimeGAN\n",
    "        \"\"\"\n",
    "        def __init__(self,hidden_dim,num_layers,padding_value=0,max_seq_len=1000):\n",
    "            super(SupervisorNetwork,self).__init__()\n",
    "            self.hidden_dim =hidden_dim\n",
    "            self.num_layers = num_layers\n",
    "            self.padding_value = padding_value\n",
    "            self.max_seq_len = max_seq_len\n",
    "\n",
    "            #supervisor architecture\n",
    "            self.sup_rnn = nn.GRU(\n",
    "                input_size=self.hidden_dim,\n",
    "                hidden_size=self.hidden_dim,\n",
    "                num_layers=self.num_layers-1,\n",
    "                batch_first=True,\n",
    "            )\n",
    "            self.sup_linear = nn.Linear(self.hidden_dim,self.hidden_dim)\n",
    "            self.sup_sigmoid = nn.Sigmoid()\n",
    "             # Init weights\n",
    "            # Default weights of TensorFlow is Xavier Uniform for W and 1 or 0 for b\n",
    "            # Reference: \n",
    "            # - https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable\n",
    "            # - https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py#L484-L614\n",
    "            with torch.no_grad():\n",
    "                for name, param in self.sup_rnn.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'bias_ih' in name:\n",
    "                        param.data.fill_(1)\n",
    "                    elif 'bias_hh' in name:\n",
    "                        param.data.fill_(0)\n",
    "                for name, param in self.sup_linear.named_parameters():\n",
    "                    if 'weight' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param)\n",
    "                    elif 'bias' in name:\n",
    "                        param.data.fill_(0)\n",
    "        def forward(self,H,T):\n",
    "            \"\"\"Forward pass for the supervisor for predicting next step\n",
    "            Args:\n",
    "                H: latent representation (B x S x E)\n",
    "                T: input temporal information (B)\n",
    "            Returns:\n",
    "                H_hat: predicted next step data (B x S x E)\n",
    "            \"\"\"\n",
    "\n",
    "            #Dynamic RNN input for ignoring paddings\n",
    "            H_pack = nn.utils.rnn.pack_padded_sequence(\n",
    "                input = H,\n",
    "                lengths=T,\n",
    "                batch_first=True,\n",
    "                enforce_sorted=False,\n",
    "            )\n",
    "\n",
    "            H_o,H_t = self.sup_rnn(H_pack)\n",
    "            #pad RNN output back to sequence length\n",
    "            H_o,T = nn.utils.rnn.pad_packed_sequence(\n",
    "                sequence=H_o,\n",
    "                batch_first=True,\n",
    "                padding_value=self.padding_value,\n",
    "                total_length=self.max_seq_len,\n",
    "            )\n",
    "            logits = self.sup_linear(H_o)\n",
    "            H_hat = self.sup_sigmoid(logits)\n",
    "            return H_hat\n",
    "\n",
    "class GeneratorNetwork(nn.Module):\n",
    "    \"\"\"The generator network for TimeGAN\n",
    "    \"\"\"\n",
    "    def __init__(self,Z_dim,hidden_dim,num_layers,padding_value=0,max_seq_len=1000):\n",
    "        super(GeneratorNetwork,self).__init__()\n",
    "        self.Z_dim = Z_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.padding_value = padding_value\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        #Generator Architecture\n",
    "        self.gen_rnn = nn.GRU(\n",
    "            input_size=self.Z_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.gen_linear = nn.Linear(self.hidden_dim,self.hidden_dim)\n",
    "        self.gen_sigmoid = nn.Sigmoid()\n",
    "                # Init weights\n",
    "        # Default weights of TensorFlow is Xavier Uniform for W and 1 or 0 for b\n",
    "        # Reference: \n",
    "        # - https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable\n",
    "        # - https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py#L484-L614\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.gen_rnn.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    torch.nn.init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    torch.nn.init.xavier_uniform_(param.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    param.data.fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    param.data.fill_(0)\n",
    "            for name, param in self.gen_linear.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    torch.nn.init.xavier_uniform_(param)\n",
    "                elif 'bias' in name:\n",
    "                    param.data.fill_(0)\n",
    "        \n",
    "    def forward(self,Z,T):\n",
    "        \"\"\" Takes in random noise (features) and generates synthetic features within the last latent space\n",
    "        Args:\n",
    "            Z: input random noise (B x S x Z)\n",
    "            T: input temporal information (B)\n",
    "        Returns:\n",
    "            H: embeddings (B x S x E)\n",
    "        \"\"\"\n",
    "        #Dynamic RNN input for ignoring paddings\n",
    "        Z_pack = nn.utils.rnn.pack_padded_sequence(\n",
    "            input = Z,\n",
    "            lengths=T,\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False,\n",
    "        )\n",
    "\n",
    "        # 128*100*71\n",
    "        H_o,H_t = self.gen_rnn(Z_pack)\n",
    "\n",
    "        #pad RNN output back to sequence length\n",
    "\n",
    "        H_o,T = nn.utils.rnn.pad_packed_sequence(\n",
    "            sequence=H_o,\n",
    "            batch_first=True,\n",
    "            padding_value=self.padding_value,\n",
    "            total_length=self.max_seq_len,\n",
    "        )\n",
    "\n",
    "        #128*100*10\n",
    "        logits = self.gen_linear(H_o)\n",
    "        H = self.gen_sigmoid(logits)\n",
    "\n",
    "        return H\n",
    "\n",
    "class DiscriminatorNetwork(nn.Module):\n",
    "    \"\"\"The discriminator network for TimeGAN\n",
    "    \"\"\"\n",
    "    def __init__(self,hidden_dim,num_layers,padding_value=0,max_seq_len=1000   ):\n",
    "        super(DiscriminatorNetwork,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.padding_value = padding_value\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        #Discriminator Architecture\n",
    "        self.dis_rnn = nn.GRU(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dis_linear = nn.Linear(self.hidden_dim,1)\n",
    "\n",
    "        # Init weights\n",
    "        # Default weights of TensorFlow is Xavier Uniform for W and 1 or 0 for b\n",
    "        # Reference: \n",
    "        # - https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable\n",
    "        # - https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py#L484-L614\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.dis_rnn.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    torch.nn.init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    torch.nn.init.xavier_uniform_(param.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    param.data.fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    param.data.fill_(0)\n",
    "            for name, param in self.dis_linear.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    torch.nn.init.xavier_uniform_(param)\n",
    "                elif 'bias' in name:\n",
    "                    param.data.fill_(0)\n",
    "    \n",
    "    def forward(self, H, T):\n",
    "        \"\"\" Forward pass for predicting if the data is real or synthetic\n",
    "        \n",
    "        Args:\n",
    "            H: latent representation (B x S x E)\n",
    "            T: input temporal information (B)\n",
    "        Returns:\n",
    "        logits: prediction logits(B x S x 1)\n",
    "        \"\"\"\n",
    "        # dynamic RNN input for ignoring paddings\n",
    "        H_pack = nn.utils.rnn.pack_padded_sequence(\n",
    "            input = H,\n",
    "            lengths=T,\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False,\n",
    "        )\n",
    "\n",
    "        # 128*100*10\n",
    "        H_o,H_t = self.dis_rnn(H_pack)\n",
    "\n",
    "        # pad RNN output back to sequence length\n",
    "        H_o,T = nn.utils.rnn.pad_packed_sequence(\n",
    "            sequence=H_o,\n",
    "            batch_first=True,\n",
    "            padding_value=self.padding_value,\n",
    "            total_length=self.max_seq_len,\n",
    "        )\n",
    "\n",
    "        logits = self.dis_linear(H_o).squeeze(-1)\n",
    "        return logits\n",
    "\n",
    "class TimeGAN(nn.Module):\n",
    "    \"\"\" Implementation of TimeGan (Yoon et al., 2019) using PyTorch\n",
    "    \n",
    "    Reference:\n",
    "        - Yoon, J., Jarret, D., van der Schaar, M. (2019). Time-series Generative Adversarial Networks. (https://papers.nips.cc/paper/2019/hash/c9efe5f26cd17ba6216bbe2a7d26d490-Abstract.html)\n",
    "        - https://github.com/jsyoon0823/TimeGAN\n",
    "    \"\"\"\n",
    "    def __init__(self,device,feature_dim,Z_dim,hidden_dim,max_seq_len,batch_size,num_layers,padding_value):\n",
    "        super(TimeGAN,self).__init__()\n",
    "        self.device =device\n",
    "        self.feature_dim = feature_dim\n",
    "        self.Z_dim = Z_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layer = num_layers\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "        self.embedder = EmbeddingNetwork(feature_dim=feature_dim,hidden_dim=hidden_dim,num_layers=num_layers,padding_value=padding_value,max_seq_len=max_seq_len)\n",
    "        self.recovery = RecoveryNetwork(feature_dim=feature_dim,hidden_dim=hidden_dim,num_layers=num_layers,padding_value=padding_value,max_seq_len=max_seq_len)\n",
    "        self.generator = GeneratorNetwork(Z_dim=Z_dim,hidden_dim=hidden_dim,num_layers=num_layers,padding_value=padding_value,max_seq_len=max_seq_len)\n",
    "        self.discriminator = DiscriminatorNetwork(hidden_dim=hidden_dim,num_layers=num_layers,padding_value=padding_value,max_seq_len=max_seq_len)\n",
    "\n",
    "        self.supervisor = SupervisorNetwork(hidden_dim=hidden_dim,num_layers=num_layers,padding_value=padding_value,max_seq_len=max_seq_len)\n",
    "\n",
    "    def _recovery_forward(self, X, T):\n",
    "        \"\"\" The embedding network forward pass and the embedder network loss\n",
    "        Args:\n",
    "            X: input features\n",
    "            T: input temporal information\n",
    "        Returns:\n",
    "            E_loss: the reconstruction loss\n",
    "            X_tilde: the reconstructed features\n",
    "        \"\"\"\n",
    "\n",
    "        # FOrward pass\n",
    "        H = self.embedder(X,T)\n",
    "        X_tilde = self.recovery(H,T)\n",
    "\n",
    "        #for Joint training\n",
    "        H_hat_supervise = self.supervisor(H,T)\n",
    "        G_loss_S = F.mse_loss(\n",
    "            H_hat_supervise[:,:-1,:],\n",
    "            H[:,1:,:],\n",
    "        ) #Teacher forcing next output\n",
    "\n",
    "        #Reconstruction loss\n",
    "        E_loss_T0 = F.mse_loss(X_tilde,X)\n",
    "        E_loss0 = 10*torch.sqrt(E_loss_T0)\n",
    "        E_loss = E_loss0 + 0.1*G_loss_S\n",
    "        return E_loss, E_loss0,E_loss_T0\n",
    "    def _supervisor_forward(self, X, T):\n",
    "        \"\"\" The supervisor training forward pass\n",
    "        Args:\n",
    "            X: original input features\n",
    "            T: input temporal information\n",
    "        Returns:\n",
    "            S_loss: the supervisor's loss\n",
    "        \"\"\"\n",
    "        #supervisor forward pass\n",
    "        H = self.embedder(X,T)\n",
    "        H_hat_supervise = self.supervisor(H,T)\n",
    "\n",
    "        #supervised loss\n",
    "        S_loss = F.mse_loss(\n",
    "            H_hat_supervise[:,:-1,:],\n",
    "            H[:,1:,:],\n",
    "        ) #Teacher forcing next output\n",
    "        return S_loss\n",
    "    def _discriminator_forward(self, X, T, Z, gamma=1):\n",
    "        \"\"\" The discriminator forward pass and adversarial loss\n",
    "        Args:\n",
    "            X: input features\n",
    "            T: input temporal information\n",
    "            Z: input noise\n",
    "            gamma: the weight for the adversarial loss\n",
    "        Returns:\n",
    "            D_loss: adversarial loss\n",
    "        \"\"\"\n",
    "        #Real\n",
    "        H = self.embedder(X, T).detach()\n",
    "\n",
    "        #generator\n",
    "        E_hat = self.generator(Z,T).detach()\n",
    "        H_hat = self.supervisor(E_hat,T).detach()\n",
    "        \n",
    "        #forward pass\n",
    "        Y_real = self.discriminator(H,T)        #Encode original data\n",
    "        Y_fake = self.discriminator(H_hat,T)    #Output of generator + supervisor\n",
    "        Y_fake_e = self.discriminator(E_hat,T)  #Output of generator\n",
    "\n",
    "        D_loss_real = F.binary_cross_entropy_with_logits(Y_real, torch.ones_like(Y_real))\n",
    "        D_loss_fake = F.binary_cross_entropy_with_logits(Y_fake, torch.zeros_like(Y_fake))\n",
    "        D_loss_fake_e = F.binary_cross_entropy_with_logits(Y_fake_e, torch.zeros_like(Y_fake_e))\n",
    "\n",
    "        D_loss = D_loss_real + D_loss_fake + gamma * D_loss_fake_e\n",
    "\n",
    "        return D_loss\n",
    "    \n",
    "    def _generator_forward(self, X, T, Z, gamma=1):\n",
    "        \"\"\" The generator forward pass\n",
    "        Args:\n",
    "            X: original input features\n",
    "            T: input temporal information\n",
    "            Z: input noise for the generator\n",
    "            gamma: the weight for the adversarial loss\n",
    "        Returns:\n",
    "            G_loss: the generator loss\n",
    "        \"\"\"\n",
    "        #supervisor forward pass\n",
    "        H = self.embedder(X,T)\n",
    "        H_hat_supervise = self.supervisor(H,T)\n",
    "\n",
    "        #generator forward pass\n",
    "        E_hat = self.generator(Z,T)\n",
    "        H_hat = self.supervisor(E_hat,T)\n",
    "\n",
    "        #synthetic data generated\n",
    "        X_hat = self.recovery(H_hat,T)\n",
    "\n",
    "        #generator loss\n",
    "        #Adversarial loss\n",
    "        Y_fake = self.discriminator(H_hat,T)        #Output of supervisor\n",
    "        Y_fake_e = self.discriminator(E_hat,T)      #Output of generator\n",
    "\n",
    "        G_loss_U = F.binary_cross_entropy_with_logits(Y_fake, torch.ones_like(Y_fake))\n",
    "        G_loss_U_e = F.binary_cross_entropy_with_logits(Y_fake_e, torch.ones_like(Y_fake_e))\n",
    "\n",
    "        #Supervised loss\n",
    "        G_loss_S = F.mse_loss(\n",
    "            H_hat_supervise[:,:-1,:],\n",
    "            H[:,1:,:],\n",
    "        ) #Teacher forcing next output\n",
    "\n",
    "        #Two moments losses\n",
    "        G_loss_V1 = torch.mean(\n",
    "            torch.abs(torch.sqrt(X_hat.var(dim=0,unbiased=False)+1e-6) - torch.sqrt(X.var(dim=0,unbiased=False)+1e-6))\n",
    "        )\n",
    "        G_loss_V2 = torch.mean(torch.abs((X_hat.mean(dim=0)) - (X.mean(dim=0))))\n",
    "        G_loss_V = G_loss_V1 + G_loss_V2\n",
    "        \n",
    "        #sum of losses\n",
    "        G_loss = G_loss_U + gamma * G_loss_U_e + 100 * torch.sqrt(G_loss_S) + 100 * G_loss_V\n",
    "    \n",
    "        return G_loss\n",
    "    \n",
    "    def _inference(self, Z,T):\n",
    "        \"\"\" Inference for generating synthetic data\n",
    "        Args:\n",
    "            Z: input noise\n",
    "            T: temporal information\n",
    "        Returns:\n",
    "            X_hat: the generated data\n",
    "        \"\"\"\n",
    "\n",
    "        #generator forward pass\n",
    "        E_hat = self.generator(Z,T)\n",
    "        H_hat = self.supervisor(E_hat,T)\n",
    "\n",
    "        #synthetic data generated\n",
    "        X_hat = self.recovery(H_hat,T)\n",
    "        return X_hat\n",
    "\n",
    "    def forward(self,X,T,Z, obj, gamma=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: input features (B,H,F)\n",
    "            T: The temporal information (B)\n",
    "            Z: the sampled noise (B,H,Z)\n",
    "            obj: the network to be trained ('autoencoder','supervisor','generator','discriminator')\n",
    "            gamma: loss hyperparameter\n",
    "        Returns:\n",
    "            loss: loss for the forward pass\n",
    "            X_hat: the generated data\n",
    "        \"\"\"\n",
    "\n",
    "        #Move variables to device\n",
    "        if obj !='inference':\n",
    "            if X is None:\n",
    "                run.stop()\n",
    "                raise ValueError('X cannot be empty')\n",
    "                \n",
    "            \n",
    "            X = torch.FloatTensor(X)\n",
    "            X = X.to(self.device)\n",
    "\n",
    "        if Z is not None:\n",
    "            Z = torch.FloatTensor(Z)\n",
    "            Z = Z.to(self.device)\n",
    "        \n",
    "        if obj == 'autoencoder':\n",
    "            #embedder and recovery forward\n",
    "            loss = self._recovery_forward(X,T)\n",
    "        elif obj == 'supervisor':\n",
    "            loss = self._supervisor_forward(X,T)\n",
    "        elif obj == 'generator':\n",
    "            if Z is None:\n",
    "                run.stop()\n",
    "                raise ValueError('Z cannot be empty')\n",
    "                \n",
    "            loss = self._generator_forward(X,T,Z,gamma)\n",
    "        elif obj == 'discriminator':\n",
    "            if Z is None:\n",
    "                run.stop()\n",
    "                raise ValueError('Z cannot be empty')\n",
    "            loss = self._discriminator_forward(X,T,Z,gamma)\n",
    "            return loss\n",
    "        elif obj == 'inference':\n",
    "            X_hat = self._inference(Z,T)\n",
    "            #X_hat = X_hat.cpu.detach()\n",
    "            X_hat = X_hat.detach().cpu()\n",
    "\n",
    "            return X_hat\n",
    "        else:\n",
    "            run.stop()\n",
    "            raise ValueError('obj must be autoencoder, supervisor, generator or discriminator')\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_trainer(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        e_opt: torch.optim.Optimizer,\n",
    "        r_opt: torch.optim.Optimizer,\n",
    "        emb_epochs: int,\n",
    "        writer \n",
    "):\n",
    "    \"\"\"\n",
    "    Training loop for embedding and recovery functions.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train\n",
    "        dataloader (torch.utils.data.DataLoader): The dataloader to use\n",
    "        e_opt (torch.optim.Optimizer): The optimizer for the embedding function\n",
    "        r_opt (torch.optim.Optimizer): The optimizer for the recovery function\n",
    "        args (Dict): The model/training configuration\n",
    "        writer (SummaryWriter): Neptune logger\n",
    "    \"\"\"\n",
    "    logger = trange(emb_epochs, desc =f\"Epoch:0, Loss:0\")\n",
    "    for epoch in logger:\n",
    "        for X_mb,T_mb in dataloader:\n",
    "\n",
    "            #reset gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            #forward pass\n",
    "            _,E_loss0,E_loss_T0 = model(X=X_mb,T=T_mb,Z=None,obj=\"autoencoder\")\n",
    "            loss = np.sqrt(E_loss_T0.item())\n",
    "\n",
    "            #backward pass\n",
    "            E_loss0.backward()\n",
    "\n",
    "            #update weights\n",
    "            e_opt.step()\n",
    "            r_opt.step()\n",
    "\n",
    "        # Log loss for final batch of each epochs\n",
    "        logger.set_description(f\"Epoch:{epoch}, Loss:{loss:.4f}\")\n",
    "        writer['Embedding/Training_loss'].append(loss)\n",
    "        \"\"\"if writer:\n",
    "            writer.add_scalar(\"Embedding/Loss:\",loss,epoch)\n",
    "            writer.flush()\"\"\"\n",
    "\n",
    "def supervisor_trainer(\n",
    "    model: torch.nn.Module, \n",
    "    dataloader: torch.utils.data.DataLoader, \n",
    "    s_opt: torch.optim.Optimizer, \n",
    "    g_opt: torch.optim.Optimizer,\n",
    "    sup_epochs: int,\n",
    "    writer\n",
    "):\n",
    "    \"\"\"\n",
    "    The training loop for the supervisor function\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train\n",
    "        dataloader (torch.utils.data.DataLoader): The dataloader to use\n",
    "        s_opt (torch.optim.Optimizer): The optimizer for the supervisor function\n",
    "        g_opt (torch.optim.Optimizer): The optimizer for the generator function\n",
    "        args (Dict): The model/training configuration\n",
    "        writer (Union[torch.utils.tensorboard.SummaryWriter, type(None)], optional): The tensorboard writer to use. Defaults to None.\n",
    "    \"\"\"\n",
    "    logger = trange(sup_epochs, desc=f\"Epoch: 0, Loss: 0\")\n",
    "    for epoch in logger:\n",
    "        for X_mb, T_mb in dataloader:\n",
    "            # Reset gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            S_loss = model(X=X_mb, T=T_mb, Z=None, obj=\"supervisor\")\n",
    "\n",
    "            # Backward Pass\n",
    "            S_loss.backward()\n",
    "            loss = np.sqrt(S_loss.item())\n",
    "\n",
    "            # Update model parameters\n",
    "            s_opt.step()\n",
    "\n",
    "        # Log loss for final batch of each epoch (29 iters)\n",
    "        logger.set_description(f\"Epoch: {epoch}, Loss: {loss:.4f}\")\n",
    "        writer['Supervisor/Training_loss'].append(loss)\n",
    "        \"\"\"if writer:\n",
    "            writer.add_scalar(\n",
    "                \"Supervisor/Loss:\",loss,epoch)\n",
    "            writer.flush()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_trainer(\n",
    "    model: torch.nn.Module, \n",
    "    dataloader: torch.utils.data.DataLoader, \n",
    "    e_opt: torch.optim.Optimizer, \n",
    "    r_opt: torch.optim.Optimizer, \n",
    "    s_opt: torch.optim.Optimizer, \n",
    "    g_opt: torch.optim.Optimizer, \n",
    "    d_opt: torch.optim.Optimizer,\n",
    "    sup_epochs: int,\n",
    "    batch_size: int,\n",
    "    max_seq_len: int,\n",
    "    Z_dim: int,\n",
    "    dis_thresh: float,\n",
    "    writer\n",
    "    ):\n",
    "    \"\"\"\n",
    "    The training loop for training the model altogether\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train\n",
    "        dataloader (torch.utils.data.DataLoader): The dataloader to use\n",
    "        e_opt (torch.optim.Optimizer): The optimizer for the embedding function\n",
    "        r_opt (torch.optim.Optimizer): The optimizer for the recovery function\n",
    "        s_opt (torch.optim.Optimizer): The optimizer for the supervisor function\n",
    "        g_opt (torch.optim.Optimizer): The optimizer for the generator function\n",
    "        d_opt (torch.optim.Optimizer): The optimizer for the discriminator function\n",
    "        args (Dict): The model/training configuration\n",
    "        writer (Union[torch.utils.tensorboard.SummaryWriter, type(None)], optional): The tensorboard writer to use. Defaults to None.\n",
    "    \"\"\"\n",
    "    logger = trange(\n",
    "        sup_epochs, \n",
    "        desc=f\"Epoch: 0, E_loss: 0, G_loss: 0, D_loss: 0\"\n",
    "    )\n",
    "    for epoch in logger:\n",
    "        for X_mb, T_mb in dataloader:\n",
    "            ## Generator Training\n",
    "            for _ in range(2):\n",
    "                # Random Generator\n",
    "                Z_mb = torch.rand((batch_size, max_seq_len, Z_dim))\n",
    "\n",
    "                # Forward Pass (Generator)\n",
    "                model.zero_grad()\n",
    "                G_loss = model(X=X_mb, T=T_mb, Z=Z_mb, obj=\"generator\")\n",
    "                G_loss.backward()\n",
    "                G_loss = np.sqrt(G_loss.item())\n",
    "\n",
    "                # Update model parameters\n",
    "                g_opt.step()\n",
    "                s_opt.step()\n",
    "\n",
    "                # Forward Pass (Embedding)\n",
    "                model.zero_grad()\n",
    "                E_loss, _, E_loss_T0 = model(X=X_mb, T=T_mb, Z=Z_mb, obj=\"autoencoder\")\n",
    "                E_loss.backward()\n",
    "                E_loss = np.sqrt(E_loss.item())\n",
    "                \n",
    "                # Update model parameters\n",
    "                e_opt.step()\n",
    "                r_opt.step()\n",
    "\n",
    "            # Random Generator\n",
    "            Z_mb = torch.rand((batch_size, max_seq_len, Z_dim))\n",
    "\n",
    "            ## Discriminator Training\n",
    "            model.zero_grad()\n",
    "            # Forward Pass\n",
    "            D_loss = model(X=X_mb, T=T_mb, Z=Z_mb, obj=\"discriminator\")\n",
    "\n",
    "            # Check Discriminator loss\n",
    "            if D_loss > dis_thresh:\n",
    "                # Backward Pass\n",
    "                D_loss.backward()\n",
    "\n",
    "                # Update model parameters\n",
    "                d_opt.step()\n",
    "            D_loss = D_loss.item()\n",
    "\n",
    "        logger.set_description(\n",
    "            f\"Epoch: {epoch}, E: {E_loss:.4f}, G: {G_loss:.4f}, D: {D_loss:.4f}\"\n",
    "        )\n",
    "        \n",
    "        writer['Joint/E_loss'].append(E_loss)\n",
    "        writer['Joint/G_loss'].append(G_loss)\n",
    "        writer['Joint/D_loss'].append(D_loss)\n",
    "\n",
    "def timegan_trainer(model,train_data,train_time,batch_size,lr,emb_epochs,sup_epochs,max_seq_length,Z_dim,dis_thresh,device,model_path,writer):\n",
    "    \"\"\"\n",
    "    The trainign procedure for TimeGAN.\n",
    "    Args:\n",
    "        model (torch.nn.module): The model that generates synthetic data\n",
    "        loaded_data(pandas.DataFrame): The data to train on, including data and time\n",
    "        args (Dict): The model/training configuration\n",
    "    Returns:\n",
    "        generated_data (np.array): The synthetic data generated by the model\n",
    "    \"\"\"\n",
    "    dataset = TimeGAN_Dataset(data=train_data,time=train_time)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.to(device)\n",
    "\n",
    "    #initialize optimizers\n",
    "    e_opt = torch.optim.Adam(model.embedder.parameters(), lr=lr)\n",
    "    r_opt = torch.optim.Adam(model.recovery.parameters(), lr=lr)\n",
    "    s_opt = torch.optim.Adam(model.supervisor.parameters(), lr=lr)\n",
    "    g_opt = torch.optim.Adam(model.generator.parameters(), lr=lr)\n",
    "    d_opt = torch.optim.Adam(model.discriminator.parameters(), lr=lr)\n",
    "\n",
    "    #initialize tensorboard writer\n",
    "    #writer = SummaryWriter(os.path.join(f\"tensorboard/{args.exp}\"))\n",
    "\n",
    "    print(\"\\nStart Embedding Network Training\")\n",
    "    embedding_trainer(model=model, dataloader=dataloader, e_opt=e_opt, r_opt=r_opt, emb_epochs=emb_epochs,writer=writer)\n",
    "\n",
    "    print(\"\\nStart Training with Supervised Loss Only\")\n",
    "    supervisor_trainer(model=model, dataloader=dataloader, s_opt=s_opt,g_opt=g_opt, sup_epochs=sup_epochs,writer=writer)\n",
    "\n",
    "    print(\"\\nStart Joint Training\")\n",
    "    joint_trainer(model=model, dataloader=dataloader, e_opt=e_opt, r_opt=r_opt, s_opt=s_opt, g_opt=g_opt, d_opt=d_opt, sup_epochs=sup_epochs, batch_size=batch_size, max_seq_len=max_seq_length, Z_dim=Z_dim, dis_thresh=dis_thresh,writer=writer)\n",
    "\n",
    "\n",
    "    #save model,args, and hyperparameters\n",
    "    #torch.save(args,f\"{args.model_path}/args.pickle\")\n",
    "    torch.save(model.state_dict(),f\"{model_path}/model.pt\")\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def timegan_generator(model,T,model_path,batch_size, max_seq_len, Z_dim ,device):\n",
    "    \"\"\"\n",
    "    The interference procedure for TimeGAN.\n",
    "    Args:\n",
    "        model (torch.nn.module): The model that generates synthetic data\n",
    "        T (List[int]): The time to generate data for\n",
    "        args (Dict): The model/training configuration\n",
    "    returns:\n",
    "        generated_data (np.array): The synthetic data generated by the model\n",
    "    \"\"\"\n",
    "    #load model\n",
    "    if not os.path.exists(model_path):\n",
    "        run.stop()\n",
    "        raise ValueError(f\"Model not found at {model_path}\")\n",
    "    model.load_state_dict(torch.load(f\"{model_path}/model.pt\"))\n",
    "    print(\"\\nStart Generating Synthetic Data\")\n",
    "    #Initialize model to evaluation mode and run without gradients\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Random Generator\n",
    "        Z = torch.rand((batch_size, max_seq_len, Z_dim))\n",
    "        # Forward Pass (Generator)\n",
    "        generated_data = model(X=None, T=T, Z=Z, obj=\"inference\")\n",
    "    return generated_data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_limit=None,save_dataset=None):\n",
    "    \"\"\"\n",
    "    data_limit=None,save_dataset=None\n",
    "    Load and preprocess real life datasets.\n",
    "    \n",
    "    Args:\n",
    "        data_limit (int): The number of data points to load. If None, all data points are loaded. Default: None. Used for testing.\n",
    "        save_dataset (bool): If 'Full', the dataset is saved to a csv file. If it's 'limited', than save the limited dataset if data_limit is not None. Default: None.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        dataset (pandas.DataFrame): The dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    main_dataset = pd.DataFrame()\n",
    "    cluster = True\n",
    "    if cluster == False:\n",
    "        Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "        filenames = askopenfilenames() # show an \"Open\" dialog box and return the path to the selected file\n",
    "        print(filenames)\n",
    "        for filename in filenames:\n",
    "            \n",
    "            if filename.endswith('.mat'):\n",
    "                #output df format: [id,value_array]\n",
    "                df = load_mat_as_df(filename)\n",
    "                print(df)\n",
    "            \n",
    "            elif filename.endswith('.csv'):\n",
    "\n",
    "                #use create_dataset_csv.py to create a csv file\n",
    "                if filename.find('dataset') != -1:\n",
    "                    df = pd.read_csv(filename,sep=';',index_col=0)\n",
    "\n",
    "                \"\"\" CSV format:\n",
    "                ID|time|Sleeping stage|length|additional_info\n",
    "\n",
    "                \"\"\"\n",
    "                pass\n",
    "\n",
    "            elif filename.endswith('.xml'):\n",
    "                ## TODO: add xml support\n",
    "                #df =\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Unsupported file format, skipping file:\",filename,\".\")\n",
    "                pass\n",
    "        \n",
    "            main_dataset.append(df)\n",
    "    else:\n",
    "        #load datasets from cluster\n",
    "        filename = \"Data/generated_dataset.csv\"\n",
    "        main_dataset = pd.read_csv(filename,sep=';',index_col=0)\n",
    "\n",
    "    #Cut df to data_limit size for testing purposes\n",
    "    if data_limit is not None:\n",
    "        if data_limit < len(main_dataset):\n",
    "            print(f'The length of the dataset is {len(main_dataset)}, the new length is {data_limit}')\n",
    "            main_dataset = main_dataset[:data_limit]\n",
    "        elif data_limit >= len(main_dataset):\n",
    "            print(\"data_limit is bigger than the dataset size, using the whole dataset\")\n",
    "    elif data_limit <= 0 or data_limit == '':\n",
    "        print(\"data_limit is 0 or less, using the whole dataset\")\n",
    "    #print the headers of the dataset\n",
    "    #print(main_dataset.head())\n",
    "    # transform dataset.time and dataset.Sleeping stage to float and int\n",
    "    #print(main_dataset)\n",
    "    #main_dataset.time = main_dataset.time.apply(string_to_float_array)\n",
    "    \n",
    "    main_dataset.Sleeping_stage = main_dataset.Sleeping_stage.apply(string_to_int_array)\n",
    "    \n",
    "    #print(main_dataset.head())\n",
    "    return main_dataset #dataset as df\n",
    "\n",
    "def load_mat_as_df(mat_file_path, var_name):\n",
    "    mat = sio.loadmat(mat_file_path,simplify_cells=True)\n",
    "\n",
    "    if var_name not in list(mat.keys()):\n",
    "        var_name = get_variable_name(mat)   \n",
    "        \n",
    "\n",
    "    return pd.DataFrame(mat[var_name])\n",
    "\n",
    "def get_variable_name(loaded_mat):\n",
    "\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.title('.mat variable selector')\n",
    "    tk.Label(root, text=\"Choose a variable:\").pack()\n",
    "    choices = list(loaded_mat.keys())\n",
    "\n",
    "    variable = tk.StringVar(root)\n",
    "    variable.set(choices[0]) # default value\n",
    "    w = tk.Combobox(root, textvariable=variable,values=choices)\n",
    "\n",
    "    w.pack()\n",
    "    def ok():\n",
    "        print (\"value is:\" + variable.get())\n",
    "        root.destroy()\n",
    "    def cancel():\n",
    "        root.destroy()\n",
    "        raise InterruptedError('User cancelled, invalid variable name')\n",
    "\n",
    "    button1 = tk.Button(root, text=\"OK\", command=ok)\n",
    "    button2 = tk.Button(root, text=\"Cancel\", command=cancel)\n",
    "    button1.pack()\n",
    "    button2.pack()\n",
    "    root.mainloop()\n",
    "    \n",
    "    return variable.get()\n",
    "def string_to_float_list(s):\n",
    "    return [float(x) for x in s.strip('[]').split(',')]\n",
    "def string_to_int_list(s):\n",
    "    return [int(x) for x in s.strip('[]').split(',')]\n",
    "def string_to_float_array(s):\n",
    "    return [float(x) for x in ast.literal_eval(s)]\n",
    "def string_to_int_array(s):\n",
    "    return [int(x) for x in ast.literal_eval(s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(writer,padding_value,data_limit=None,save_dataset=None,norm_enable=False):\n",
    "    \"\"\"\n",
    "    padding_value: int = -1.0,\n",
    "    data_limit: int = None\"\"\"\n",
    "    # Load and preprocess data\n",
    "    # \n",
    "    # Steps:\n",
    "    # 0. Sanity checks\n",
    "    # 1. Load data from files (csv,mat,xml)\n",
    "    # 2. Preprocess data:\n",
    "    # 2.1. Remove outliers\n",
    "    # 2.2. Extract sequence length and time\n",
    "    # 2.3. Resample data\n",
    "    # 2.4. Normalize data\n",
    "    # 2.5. Padding\n",
    "    # 3 Save data to csv file\n",
    "    #  \n",
    "    # Args:\n",
    "    #     data_limit (int): The number of lines to load from the data file. If None, all data points are loaded. Default: None. Used for testing.\n",
    "    #     padding_value (int): The value used for padding\n",
    "    #     save_dataset (bool): If 'Full', the dataset is saved to a csv file. If it's 'limited', than save the limited dataset if data_limit is not None. Default: None.\n",
    "    #     norm_enable (bool): If True, normalize the data. Default: False.\n",
    "    #     \n",
    "    # \n",
    "    # Returns:\n",
    "    #     prep_data (pandas.DataFrame): The processed data\n",
    "\n",
    "    #######################################\n",
    "    # 0. Sanity checks\n",
    "    #######################################\n",
    "    \n",
    "    # Check if save_dataset is valid\n",
    "    if save_dataset is not None:\n",
    "        if save_dataset.lower =='none':\n",
    "            save_dataset = None\n",
    "        elif save_dataset.lower =='full':\n",
    "            save_dataset = 'Full'\n",
    "        elif save_dataset.lower =='limited':\n",
    "            save_dataset = 'Limited'\n",
    "        else:\n",
    "            raise ValueError('save_dataset must be None, Full or Limited')\n",
    "    # Check if data_limit is valid\n",
    "    if data_limit is not None:\n",
    "        if isinstance(data_limit, str) == True:\n",
    "            data_limit= None\n",
    "        elif isinstance(data_limit, float) == True and data_limit.is_integer() == True:\n",
    "            data_limit = int(data_limit)\n",
    "        elif isinstance(data_limit, int) == True:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('data_limit must be None or int')\n",
    "    # Check if padding_value is valid\n",
    "    if isinstance(padding_value, str) == True:\n",
    "        raise ValueError('padding_value must be int')\n",
    "    elif isinstance(padding_value, float) == True and padding_value.is_integer() == True:\n",
    "        padding_value = int(padding_value)\n",
    "    elif isinstance(padding_value, int) == True:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('padding_value must be int')\n",
    "    # Check if norm_enable is valid\n",
    "    if isinstance(norm_enable, bool) == True:\n",
    "        pass\n",
    "    elif isinstance(norm_enable, str) == True:\n",
    "        if norm_enable.lower() == 'true':\n",
    "            norm_enable = True\n",
    "        elif norm_enable.lower() == 'false':\n",
    "            norm_enable = False\n",
    "        else:\n",
    "            raise ValueError('norm_enable must be bool')\n",
    "    else:\n",
    "        raise ValueError('norm_enable must be bool')\n",
    "\n",
    "\n",
    "    #######################################\n",
    "    # 1. Load data from files (csv,mat,xml)\n",
    "    #######################################\n",
    "\n",
    "    loaded_data = load_data(data_limit=data_limit,save_dataset=save_dataset)\n",
    "    \"\"\"\n",
    "    loaded data =       time_data   , data  , length\n",
    "    (pandas.DataFrame), (np.array)  ,(list) ,(int)\n",
    "    \n",
    "    ()\n",
    "    \"\"\"\n",
    "    #convert data to np.array\n",
    "    #loaded_data['data'] = loaded_data['data'].apply(lambda x: np.array(x))\n",
    "    \n",
    "    #######################################\n",
    "    # 2. Preprocess data:\n",
    "    #######################################\n",
    "    # 2.1. Remove outliers\n",
    "    #######################################\n",
    "    \"\"\"\n",
    "    Remove row's with unacceptable sleep stages values\n",
    "    \"\"\"\n",
    "    \n",
    "    sleep_stages = np.array([1,2,3,4,5])\n",
    "    loaded_data[loaded_data['Sleeping_stage'].apply(lambda x: all(elem in sleep_stages for elem in x))]\n",
    "\n",
    "    #######################################\n",
    "    # 2.2. Extract sequence length and time\n",
    "    #######################################\n",
    "    \"\"\"\n",
    "    Extract sequence length of all lines and time of each line\n",
    "    \"\"\"\n",
    "    loaded_data['length'] = loaded_data['Sleeping_stage'].apply(lambda x: len(x))\n",
    "\n",
    "    #plot length distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2,figsize=(10,5))\n",
    "    ax1.hist(loaded_data['length'], )\n",
    "    ax1.set_title('Original length distribution')\n",
    "    _,bins,_=ax1.hist(loaded_data['length'])\n",
    "    # drop rows with +- 10% of mean length\n",
    "    #caluclate mean length \n",
    "    mean_len = loaded_data.length.mean()\n",
    "    #df = df[df['Age'] <= 1.1 * mean_age]\n",
    "    loaded_data=loaded_data[loaded_data['length'] <= 1.1 *mean_len]\n",
    "    loaded_data=loaded_data[loaded_data['length'] >=0.9*mean_len]\n",
    "    ax2.hist(loaded_data['length'],bins=bins,)\n",
    "    writer['Length_comp'].upload(fig)\n",
    "    #######################################\n",
    "    # 2.4. Normalize data\n",
    "    #######################################\n",
    "    \"\"\"\n",
    "    Normalize data to [0,1] using MinMaxScaler algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    if norm_enable == True:\n",
    "        loaded_data['Sleeping_stage']=MinMaxNormalizer(loaded_data['Sleeping_stage'])\n",
    "    \n",
    "\n",
    "    #######################################\n",
    "    # 2.5. Padding\n",
    "    #######################################\n",
    "    \"\"\"\n",
    "    Padding data to given length\n",
    "    \"\"\"\n",
    "    #print(f'length of all row: {loaded_data.length}')\n",
    "    max_len = max(loaded_data['length'])\n",
    "    length = len(loaded_data)\n",
    "    #get the number of columns in the data\n",
    "    dim =len(loaded_data.columns)-1\n",
    "    print(f'dim is {dim}')\n",
    "    # Question: Current padding value is 0, is it ok? Do we need it or just resample?\n",
    "    data_info = {\n",
    "        'length' : length,\n",
    "        'max_length' : max_len,\n",
    "        'paddding_value_stage' : padding_value,\n",
    "        'dim' : dim\n",
    "    }\n",
    "\n",
    "    loaded_data['Sleeping_stage'] = loaded_data['Sleeping_stage'].apply(lambda x: np.transpose(x))\n",
    "    \n",
    "    prep_data = pd.DataFrame(columns=['Sleeping_stage','time'])\n",
    "    print(f'Padding data to {max_len} length')\n",
    "\n",
    "    #shape: [length, max_len,features] = [length, max_len,1]\n",
    "    # init empty array\n",
    "    padded_data = np.empty((length,max_len,1))\n",
    "    #fill array with padding value\n",
    "    padded_data.fill(padding_value)\n",
    "\n",
    "    time = []\n",
    "\n",
    "    for i in tqdm(range(length)):\n",
    "        #get a row of Sleep stage data\n",
    "        tmp_stage = loaded_data.iloc[i]['Sleeping_stage']\n",
    "        #print tmp_stage type\n",
    "        #print(tmp_stage.shape)\n",
    "\n",
    "        #impute missing values\n",
    "        #tmp_stage = impute_missing_values(tmp_stage)\n",
    "        \n",
    "        #get time data\n",
    "        tmp_time = len(tmp_stage)\n",
    "        #reshape tmp_stage to [tmp_time,1]\n",
    "        tmp_stage = tmp_stage.reshape(tmp_time,1)\n",
    "        # pad data to 'max_seq_len'\n",
    "        if len(tmp_stage) >= max_len:\n",
    "            padded_data[i,:,:] = tmp_stage[:max_len,0:]\n",
    "            time.append(max_len)\n",
    "        else:\n",
    "            padded_data[i,:tmp_time,:] = tmp_stage[:,0:]\n",
    "            time.append(len(tmp_stage))\n",
    "\n",
    "    return padded_data, time, data_info    \n",
    "    \n",
    "def impute_missing_values(\n",
    "        curr_data: np.ndarray,\n",
    "        )-> np.ndarray:\n",
    "    \"\"\"ArithmeticError\n",
    "    Impute missing values in data.\n",
    "    Args:\n",
    "        curr_data: 1-D array of data.\n",
    "    \n",
    "    Returns:\n",
    "        data: 1-D array of data with missing values filled.\n",
    "    \"\"\"\n",
    "    index = range(1,len(curr_data)+1)\n",
    "    curr_data = pd.DataFrame(data=curr_data,index=index,columns=['data'])\n",
    "    #impute data\n",
    "    imputed_data=curr_data.fillna(1)\n",
    "    \n",
    "    # check for any N/A values\n",
    "    if imputed_data.isnull().any().any():\n",
    "        raise ArithmeticError('Missing values were not imputed correctly')\n",
    "    print(f'imputed data is {imputed_data.data[0].dtype}')\n",
    "    return imputed_data.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(length)):\n",
    "        #create empty array with padding value\n",
    "        tmp_stage = np.empty(max_len)\n",
    "        #fill array with padding value\n",
    "        tmp_stage.fill(padding_value)\n",
    "        #fill array with data\n",
    "        print(f'padding shape {tmp_stage.shape}, while data shape is {loaded_data.iloc[i][\"Sleeping_stage\"].shape}')\n",
    "        #np.copyto(tmp_stage,loaded_data.iloc[i]['Sleeping_stage'])\n",
    "        tmp_stage[0:len(loaded_data['Sleeping_stage'][i])]=loaded_data['Sleeping_stage'][i]\n",
    "        #create empty array for padded time\n",
    "        #tmp_time = np.empty(max_len)\n",
    "        #fill array with padding value\n",
    "        #tmp_time.fill(time_pad)\n",
    "        #fill array with data\n",
    "        #np.copyto(tmp_time,loaded_data.iloc[i]['time'])\n",
    "        #tmp_time[0:len(loaded_data['time'][i])]=loaded_data['time'][i]\n",
    "\n",
    "        #append to prep_data\n",
    "        #prep_data = prep_data.append({'time':tmp_time,'Sleeping_stage':tmp_stage},ignore_index=True)\n",
    "        tmp_time = len(tmp_stage)\n",
    "        prep_data=prep_data.append({'Sleeping_stage':tmp_stage,'time':tmp_time},ignore_index=True)\n",
    "        \n",
    "\n",
    "    # add index column to prep_data\n",
    "    #prep_data['index'] = prep_data.index\n",
    "    \n",
    "\n",
    "\n",
    "    # 3.1 Save dataset to file\n",
    "    if save_dataset == 'Full':\n",
    "        #save dataset to a csv file\n",
    "        prep_data.to_csv('full_dataset.csv',sep=';')\n",
    "    elif save_dataset == 'Limited':\n",
    "        if data_limit is not None or data_limit != '' or data_limit > 0:\n",
    "            #save dataset as limited dataset\n",
    "            prep_data.to_csv('limited_dataset.csv',sep=';')\n",
    "        else:\n",
    "            print(f\"Warning: data_limit is {data_limit} which is not supported value, dataset is not limited, saving full dataset.\")\n",
    "            prep_data.to_csv('full_dataset.csv',sep=';')\n",
    "    elif save_dataset is None or save_dataset == '':\n",
    "        pass\n",
    "    else:\n",
    "        run.stop()\n",
    "        raise ValueError(\"Invalid save_dataset value, valid values are \\'Full\\',\\'Limited\\',None.\")\n",
    "    \"\"\"\n",
    "    \"\"\"for i in tqdm(range(length)):\n",
    "        #create empty array with padding value\n",
    "        tmp_array = np.empty([max_len,1])\n",
    "        tmp_array.fill(padding_value)\n",
    "        #fill array with data\n",
    "        tmp_array[:loaded_data['Sleeping_stage'][i].shape[0],:loaded_data['Sleeping_stage'][i].shape[1]] = loaded_data['Sleeping_stage'][i]\n",
    "        #append to prep_data\n",
    "        prep_data.append(tmp_array)\n",
    "    \"\"\"\n",
    "    #print data type of prepared data.time\n",
    "    #print(f'prep_data time type is {type(prep_data.time[0])}')\n",
    "    #print(f'prep_data shape is {prep_data}')\n",
    "    #print(f'prep_data time shape is {prep_data.time.shape}')\n",
    "    #print(f'prep_data Sleeping_stage shape is {prep_data.Sleeping_stage.shape}')\n",
    "    \n",
    "    #save dataset to a csv file\n",
    "    #prep_data.to_csv('test_dataset.csv',sep=';')\n",
    "\n",
    "\n",
    "    #\n",
    "\n",
    "    #return prep_data.Sleeping_stage ,prep_data.time,data_info\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def MinMaxNormalizer(data,min_value=1,max_value=5):\n",
    "    numerator = data-min_value\n",
    "    denominator = max_value-min_value\n",
    "    norm_data = numerator/denominator\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code directory:\t\t\tc:\\Users\\tomo9\\Documents\\00_School\\00_Thesis\\HypnoGAN\n",
      "Data directory:\t\t\tc:\\Users\\tomo9\\Documents\\00_School\\00_Thesis\\HypnoGAN\\Data\n",
      "Output directory:\t\tc:\\Users\\tomo9\\Documents\\00_School\\00_Thesis\\HypnoGAN\\Output\\test\n",
      "Using CUDA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# Experiment Arguments\n",
    "#######################################\n",
    "\n",
    "# select device:\n",
    "device = \"cuda\"\n",
    "\n",
    "#set random seed\n",
    "seed = 0\n",
    "\n",
    "#experiment name\n",
    "exp_name =\"test\"\n",
    "\n",
    "#normalization enable\n",
    "norm_enable = False\n",
    "\n",
    "# padding value\n",
    "padding_value = 0.0\n",
    "\n",
    "# Train\n",
    "is_train = True\n",
    "\n",
    "# dataset save:\n",
    "# Full: save full dataset\n",
    "# Limited: save limited dataset\n",
    "# None: don't save dataset\n",
    "save_dataset = None\n",
    "\n",
    "# save arguments to neptune\n",
    "run[\"Initialization/Arguments/ExperimentArgs/device\"] = device\n",
    "run[\"Initialization/Arguments/ExperimentArgs/seed\"] = seed\n",
    "run[\"Initialization/Arguments/ExperimentArgs/exp_name\"] = exp_name\n",
    "run[\"Initialization/Arguments/ExperimentArgs/norm_enable\"] = norm_enable\n",
    "run[\"Initialization/Arguments/ExperimentArgs/padding_value\"] = padding_value\n",
    "run[\"Initialization/Arguments/ExperimentArgs/is_train\"] = is_train\n",
    "#run[\"Initialization/Arguments/ExperimentArgs/save_dataset\"] = save_dataset\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Data Arguments\n",
    "#######################################\n",
    "\n",
    "#data limit for testing\n",
    "# None: use full dataset\n",
    "# int: use limited dataset\n",
    "data_limit = 140\n",
    "\n",
    "#train test split rate\n",
    "train_rate = 0.6\n",
    "# save arguments to neptune\n",
    "run[\"Initialization/Arguments/DataArgs/data_limit\"] = data_limit\n",
    "run[\"Initialization/Arguments/DataArgs/train_rate\"] = train_rate\n",
    "\n",
    "#######################################\n",
    "# Model Arguments\n",
    "#######################################\n",
    "\n",
    "# embedding model epochs\n",
    "emb_epochs = 300\n",
    "\n",
    "# GAN model epochs\n",
    "gan_epochs = 300\n",
    "\n",
    "# supervised model epochs\n",
    "sup_epochs = 300\n",
    "\n",
    "# batch size\n",
    "batch_size = 64\n",
    "\n",
    "# hidden dimension of RNN\n",
    "hidden_dim = 20\n",
    "\n",
    "# number of layers in RNN\n",
    "num_layers = 3\n",
    "\n",
    "# discriminator threshold\n",
    "dis_thresh = 0.15\n",
    "\n",
    "#learning rate\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "# save arguments to neptune\n",
    "run[\"Initialization/Arguments/ModelArgs/embedding_epochs\"] = emb_epochs\n",
    "run[\"Initialization/Arguments/ModelArgs/gan_epochs\"] = gan_epochs\n",
    "run[\"Initialization/Arguments/ModelArgs/supervised_epochs\"] = sup_epochs\n",
    "run[\"Initialization/Arguments/ModelArgs/batch_size\"] = batch_size\n",
    "run[\"Initialization/Arguments/ModelArgs/hidden_dim\"] = hidden_dim\n",
    "run[\"Initialization/Arguments/ModelArgs/num_layers\"] = num_layers\n",
    "run[\"Initialization/Arguments/ModelArgs/discriminator_threshold\"] = dis_thresh\n",
    "run[\"Initialization/Arguments/ModelArgs/learning_rate\"] = lr\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "# Initialize output directories\n",
    "######################################\n",
    "## runtime directory\n",
    "code_dir = os.path.abspath(\".\")\n",
    "if not os.path.exists(code_dir):\n",
    "    run.stop()\n",
    "    raise ValueError(f\"Code directory not found at {code_dir}\")\n",
    "\n",
    "## Data directory\n",
    "data_path = os.path.abspath(\"./Data\")\n",
    "if not os.path.exists(data_path):\n",
    "    run.stop()\n",
    "    raise ValueError(f\"Data directory not found at {data_path}\")\n",
    "data_dir = os.path.dirname(data_path)\n",
    "data__file_name = os.path.basename(data_path)\n",
    "## Output directory\n",
    "model_path = os.path.abspath(f\"./Output/{exp_name}/\")\n",
    "out_dir = os.path.abspath(model_path)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "\n",
    "print(f\"Code directory:\\t\\t\\t{code_dir}\")\n",
    "print(f\"Data directory:\\t\\t\\t{data_path}\")\n",
    "print(f\"Output directory:\\t\\t{out_dir}\")\n",
    "\n",
    " ######################################\n",
    "# Initialize random seed and CUDA\n",
    "######################################\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\" and torch.cuda.is_available():\n",
    "    print(\"Using CUDA\\n\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    print(\"Using CPU\\n\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataset is 129, the new length is 3\n",
      "dim is 3\n",
      "Padding data to 1030 length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2998.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Embedding Network Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:9, Loss:3.1416: 100%|██████████| 10/10 [00:02<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Training with Supervised Loss Only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.2660: 100%|██████████| 10/10 [00:02<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Joint Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, E: 4.0887, G: 12.6615, D: 1.9445: 100%|██████████| 10/10 [00:24<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to c:\\Users\\tomo9\\Documents\\00_School\\00_Thesis\\HypnoGAN\\Output\\test\n",
      "\n",
      "Start Generating Synthetic Data\n",
      "Generated data preview:\n",
      "[[[1.6365259 ]\n",
      "  [1.6365259 ]\n",
      "  [1.6365259 ]\n",
      "  [1.6365259 ]\n",
      "  [1.6365259 ]\n",
      "  [1.6365259 ]\n",
      "  [1.6365259 ]\n",
      "  [0.02954027]\n",
      "  [0.02954027]\n",
      "  [0.02954027]]]\n",
      "\n",
      "Model Runtime: 0.5338911175727844 mins\n",
      "\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 12 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 12 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/NTLAB/HypnoGAN/e/HYPNOG-64/metadata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "######################################\n",
    "# Load and preprocess data for model\n",
    "######################################\n",
    "X,T,loaded_data_info = preprocess_data(writer=run,padding_value=padding_value,data_limit=data_limit,save_dataset=save_dataset,norm_enable=norm_enable)\n",
    "#print(X)\n",
    "#print(f\"Processed Data: {X.shape} (Idx x Max_Sequence_Length x Features(=1))\")\n",
    "#print(X[0])\n",
    "#print(f\"Original data preview:\\n{X[:2, :10, :]}\\n\")\n",
    "feature_dim = X.shape[-1]\n",
    "Z_dim = X.shape[-1]\n",
    "#print(f'feature_dim: {feature_dim}, Z_dim: {Z_dim}')\n",
    "\n",
    "max_seq_len = loaded_data_info['max_length']\n",
    " # Train-Test Split data and time\n",
    " # TODO: Same people should be in the same pool at train test split\n",
    " # Make the split on the subject ID's, so also have to att ID to the loaded data\n",
    "train_data, test_data, train_time, test_time = train_test_split(\n",
    "    X, T, test_size=train_rate, random_state=seed\n",
    ")\n",
    "#########################\n",
    "# Initialize and Run model\n",
    "#########################\n",
    " # Log start time\n",
    "start = time.time()\n",
    "#init TimeGAN model\n",
    "model = TimeGAN(device=device,feature_dim=feature_dim,Z_dim=Z_dim,  hidden_dim=hidden_dim, num_layers=num_layers, max_seq_len=max_seq_len,batch_size=batch_size,padding_value=padding_value)\n",
    "\n",
    "#model = TimeGAN(feature_dim=feature_dim,  hidden_dim=hidden_dim, num_layers=num_layers, max_seq_len=max_seq_len,padding_value=padding_value)\n",
    "if is_train == True:\n",
    "    timegan_trainer(model,train_data,train_time,batch_size=batch_size,lr=lr,emb_epochs=emb_epochs,sup_epochs=sup_epochs,max_seq_length=max_seq_len,Z_dim=Z_dim,dis_thresh=dis_thresh,device=device,model_path=model_path,writer=run)\n",
    "generated_data = timegan_generator(model, train_time, model_path=model_path,batch_size=batch_size,max_seq_len=max_seq_len,Z_dim=Z_dim,device=device)\n",
    "generated_time = train_time\n",
    "# Log end time\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Generated data preview:\\n{generated_data[:2, -10:, :2]}\\n\")\n",
    "print(f\"Model Runtime: {(end - start)/60} mins\\n\")\n",
    "# Save splitted data and generated data\n",
    "with open(f\"{model_path}/train_data.pickle\", \"wb\") as fb:\n",
    "    run[\"pickled_train_data\"].upload(File.as_pickle(train_data))\n",
    "    pickle.dump(train_data, fb)\n",
    "with open(f\"{model_path}/train_time.pickle\", \"wb\") as fb:\n",
    "    run[\"pickled_train_time\"].upload(File.as_pickle(train_time))\n",
    "    pickle.dump(train_time, fb)\n",
    "with open(f\"{model_path}/test_data.pickle\", \"wb\") as fb:\n",
    "    run[\"pickled_test_data\"].upload(File.as_pickle(test_data))\n",
    "    pickle.dump(test_data, fb)\n",
    "with open(f\"{model_path}/test_time.pickle\", \"wb\") as fb:\n",
    "    run[\"pickled_test_time\"].upload(File.as_pickle(test_time))\n",
    "    pickle.dump(test_time, fb)\n",
    "with open(f\"{model_path}/fake_data.pickle\", \"wb\") as fb:\n",
    "    run[\"pickled_fake_data\"].upload(File.as_pickle(generated_data))\n",
    "    pickle.dump(generated_data, fb)\n",
    "with open(f\"{model_path}/fake_time.pickle\", \"wb\") as fb:\n",
    "    run[\"pickled_fake_time\"].upload(File.as_pickle(generated_time))\n",
    "    pickle.dump(generated_time, fb)\n",
    "\n",
    "# Stop Neptune experiment\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data shape: (1, 1030, 1)\n",
      "\n",
      "Generated data preview:\n",
      "[[[0.11334832]\n",
      "  [0.37210992]\n",
      "  [0.67834526]\n",
      "  ...\n",
      "  [0.02954027]\n",
      "  [0.02954027]\n",
      "  [0.02954027]]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Generated data shape: {generated_data.shape}\\n\")\n",
    "print(f\"Generated data preview:\\n{generated_data[:1, :,:]}\\n\")\n",
    "\n",
    "plt.plot(generated_data[0])\n",
    "plt.savefig(\"test1.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "\n",
    "# Evaluation variables:\n",
    "feat_pred_no = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Preprocess data for seeker\n",
    "#########################\n",
    "# Define enlarge data and its labels\n",
    "enlarge_data = np.concatenate((train_data, test_data), axis=0)\n",
    "enlarge_time = np.concatenate((train_time, test_time), axis=0)\n",
    "enlarge_data_label = np.concatenate((np.ones([train_data.shape[0], 1]), np.zeros([test_data.shape[0], 1])), axis=0)\n",
    "# Mix the order\n",
    "idx = np.random.permutation(enlarge_data.shape[0])\n",
    "enlarge_data = enlarge_data[idx]\n",
    "enlarge_data_label = enlarge_data_label[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_prediction(train_data, test_data, index):\n",
    "    \"\"\"Use the other features to predict a certain feature.\n",
    "\n",
    "    Args:\n",
    "    - train_data (train_data, train_time): training time-series\n",
    "    - test_data (test_data, test_data): testing time-series\n",
    "    - index: feature index to be predicted\n",
    "\n",
    "    Returns:\n",
    "    - perf: average performance of feature predictions (in terms of AUC or MSE)\n",
    "    \"\"\"\n",
    "    train_data, train_time = train_data\n",
    "    test_data, test_time = test_data\n",
    "\n",
    "    # Parameters\n",
    "    no, seq_len, dim = train_data.shape\n",
    "\n",
    "    # Set model parameters\n",
    "\n",
    "    args = {}\n",
    "    args[\"device\"] = \"cuda\"\n",
    "    args[\"task\"] = \"regression\"\n",
    "    args[\"model_type\"] = \"gru\"\n",
    "    args[\"bidirectional\"] = False\n",
    "    args[\"epochs\"] = 20\n",
    "    args[\"batch_size\"] = 128\n",
    "    args[\"in_dim\"] = dim-1\n",
    "    args[\"h_dim\"] = dim-1\n",
    "    args[\"out_dim\"] = 1\n",
    "    args[\"n_layers\"] = 3\n",
    "    args[\"dropout\"] = 0.5\n",
    "    args[\"padding_value\"] = -1.0\n",
    "    args[\"max_seq_len\"] = 100\n",
    "    args[\"learning_rate\"] = 1e-3\n",
    "    args[\"grad_clip_norm\"] = 5.0\n",
    "\n",
    "    # Output initialization\n",
    "    perf = list()\n",
    "  \n",
    "    # For each index\n",
    "    for idx in index:\n",
    "        # Set training features and labels\n",
    "        train_dataset = FeaturePredictionDataset(\n",
    "            train_data, \n",
    "            train_time, \n",
    "            idx\n",
    "        )\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args[\"batch_size\"],\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Set testing features and labels\n",
    "        test_dataset = FeaturePredictionDataset(\n",
    "            test_data, \n",
    "            test_time,\n",
    "            idx\n",
    "        )\n",
    "        test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=no,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # Initialize model\n",
    "        model = GeneralRNN(args)\n",
    "        model.to(args[\"device\"])\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=args[\"learning_rate\"]\n",
    "        )\n",
    "\n",
    "        logger = trange(args[\"epochs\"], desc=f\"Epoch: 0, Loss: 0\")\n",
    "        for epoch in logger:\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for train_x, train_t, train_y in train_dataloader:\n",
    "                train_x = train_x.to(args[\"device\"])\n",
    "                train_y = train_y.to(args[\"device\"])\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                train_p = model(train_x, train_t)\n",
    "                loss = criterion(train_p, train_y)\n",
    "                # backward\n",
    "                loss.backward()\n",
    "                # optimize\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            logger.set_description(f\"Epoch: {epoch}, Loss: {running_loss:.4f}\")\n",
    "\n",
    "        \n",
    "        # Evaluate the trained model\n",
    "        with torch.no_grad():\n",
    "            temp_perf = 0\n",
    "            for test_x, test_t, test_y in test_dataloader:\n",
    "                test_x = test_x.to(args[\"device\"])\n",
    "                test_p = model(test_x, test_t).cpu().numpy()\n",
    "\n",
    "                test_p = np.reshape(test_p, [-1])\n",
    "                test_y = np.reshape(test_y.numpy(), [-1])\n",
    "        \n",
    "                temp_perf = rmse_error(test_y, test_p)\n",
    "      \n",
    "        perf.append(temp_perf)\n",
    "    \n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_idx = np.random.permutation(train_data.shape[2])[:feat_pred_no]\n",
    "print(\"Running feature prediction using original data...\")\n",
    "ori_feat_pred_perf = feature_prediction(\n",
    "    (train_data, train_time), \n",
    "    (test_data, test_time),\n",
    "    feat_idx\n",
    ")\n",
    "print(\"Running feature prediction using generated data...\")\n",
    "new_feat_pred_perf = feature_prediction(\n",
    "    (generated_data, generated_time),\n",
    "    (test_data, test_time),\n",
    "    feat_idx\n",
    ")\n",
    "feat_pred = [ori_feat_pred_perf, new_feat_pred_perf]\n",
    "print('Feature prediction results:\\n' +\n",
    "      f'(1) Ori: {str(np.round(ori_feat_pred_perf, 4))}\\n' +\n",
    "      f'(2) New: {str(np.round(new_feat_pred_perf, 4))}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def string_to_int_array(s):\n",
    "    return [int(x) for x in ast.literal_eval(s)]\n",
    "\n",
    "def dismantle_array(array):\n",
    "    \"\"\"Dismantle ID x length x 1 array to ID x length x 5 based on x1 values.\"\"\"\n",
    "    print(f'array shape: {array.shape}')\n",
    "    \n",
    "    new_array = np.zeros((array.shape[0],array.shape[1],6))\n",
    "    i_max = array.shape[0]-1\n",
    "    j_max = array.shape[1]-1\n",
    "    for i in range(i_max):\n",
    "        for j in range(j_max):\n",
    "            new_array[i,j,int(array[i,j,0])] = 1\n",
    "    print(new_array.shape)\n",
    "    print(new_array[0,0,:])\n",
    "    return new_array\n",
    "def remake_array(array):\n",
    "    \"\"\"Remake ID x length x 5 array to ID x length x 1 based on x1 values.\"\"\"\n",
    "    print(f'array shape: {array.shape}')\n",
    "    \n",
    "    new_array = np.zeros((array.shape[0],array.shape[1],1))\n",
    "    i_max = array.shape[0]-1\n",
    "    j_max = array.shape[1]-1\n",
    "    for i in range(i_max):\n",
    "        for j in range(j_max):\n",
    "            new_array[i,j,0] = np.argmax(array[i,j,:])\n",
    "    print(new_array.shape)\n",
    "    print(new_array[0,0,:])\n",
    "    return new_array\n",
    "\n",
    "def load_data(data_limit=1000):\n",
    "    \"\"\"\n",
    "    data_limit=None,save_dataset=None\n",
    "    Load and preprocess real life datasets.\n",
    "    \n",
    "    Args:\n",
    "        data_limit (int): The number of data points to load. If None, all data points are loaded. Default: None. Used for testing.\n",
    "        save_dataset (bool): If 'Full', the dataset is saved to a csv file. If it's 'limited', than save the limited dataset if data_limit is not None. Default: None.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        dataset (pandas.DataFrame): The dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    main_dataset = pd.DataFrame()\n",
    "\n",
    "\t#load datasets from cluster\n",
    "    filename = \"Data/generated_dataset_ABC.csv\"\n",
    "    main_dataset = pd.read_csv(filename,sep=';',index_col=0)\n",
    "\n",
    "    #Cut df to data_limit size for testing purposes\n",
    "    if data_limit is not None:\n",
    "        if data_limit < len(main_dataset):\n",
    "            print(f'The length of the dataset is {len(main_dataset)}, the new length is {data_limit}')\n",
    "            main_dataset = main_dataset[:data_limit]\n",
    "        elif data_limit >= len(main_dataset):\n",
    "            print(\"data_limit is bigger than the dataset size, using the whole dataset\")\n",
    "    elif data_limit <= 0 or data_limit == '':\n",
    "        print(\"data_limit is 0 or less, using the whole dataset\")\n",
    "   \n",
    "    main_dataset.Sleeping_stage = main_dataset.Sleeping_stage.apply(string_to_int_array)\n",
    "    \n",
    "    return main_dataset #dataset as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_limit is bigger than the dataset size, using the whole dataset\n",
      "dim is 2\n",
      "Padding data to 1101 length\n",
      "array shape: (125, 1101, 1)\n",
      "(125, 1101, 6)\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "array shape: (125, 1101, 6)\n",
      "(125, 1101, 1)\n",
      "[1.]\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[3.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  ...\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  ...\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2574e091840>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "#######################################\n",
    "# 1. Load data from files (csv,mat,xml)\n",
    "#######################################\n",
    "\n",
    "loaded_data = load_data()\n",
    "\"\"\"\n",
    "loaded data =       time_data   , data  , length\n",
    "(pandas.DataFrame), (np.array)  ,(list) ,(int)\n",
    "\n",
    "()\n",
    "\"\"\"\n",
    "#convert data to np.array\n",
    "#loaded_data['data'] = loaded_data['data'].apply(lambda x: np.array(x))\n",
    "\n",
    "#######################################\n",
    "# 2. Preprocess data:\n",
    "#######################################\n",
    "# 2.1. Remove outliers\n",
    "#######################################\n",
    "\"\"\"\n",
    "Remove row's with unacceptable sleep stages values\n",
    "\"\"\"\n",
    "\n",
    "sleep_stages = np.array([1,2,3,4,5])\n",
    "loaded_data[loaded_data['Sleeping_stage'].apply(lambda x: all(elem in sleep_stages for elem in x))]\n",
    "\n",
    "#######################################\n",
    "# 2.2. Extract sequence length and time\n",
    "#######################################\n",
    "\"\"\"\n",
    "Extract sequence length of all lines and time of each line\n",
    "\"\"\"\n",
    "loaded_data['length'] = loaded_data['Sleeping_stage'].apply(lambda x: len(x))\n",
    "\n",
    "#plot length distribution\n",
    "#fig, (ax1, ax2) = plt.subplots(ncols=2,figsize=(10,5))\n",
    "#ax1.hist(loaded_data['length'], )\n",
    "#ax1.set_title('Original length distribution')\n",
    "#_,bins,_=ax1.hist(loaded_data['length'])\n",
    "# drop rows with +- 10% of mean length\n",
    "#caluclate mean length \n",
    "mean_len = loaded_data.length.mean()\n",
    "#df = df[df['Age'] <= 1.1 * mean_age]\n",
    "loaded_data=loaded_data[loaded_data['length'] <= 1.1 *mean_len]\n",
    "loaded_data=loaded_data[loaded_data['length'] >=0.9*mean_len]\n",
    "#ax2.hist(loaded_data['length'],bins=bins,)\n",
    "#writer['Length_comp'].upload(fig)\n",
    "#######################################\n",
    "# 2.4. Normalize data\n",
    "#######################################\n",
    "\"\"\"\n",
    "Normalize data to [0,1] using MinMaxScaler algorithm\n",
    "\"\"\"\n",
    "\n",
    "#######################################\n",
    "# 2.5. Padding\n",
    "#######################################\n",
    "\"\"\"\n",
    "Padding data to given length\n",
    "\"\"\"\n",
    "#print(f'length of all row: {loaded_data.length}')\n",
    "max_len = max(loaded_data['length'])\n",
    "length = len(loaded_data)\n",
    "#get the number of columns in the data\n",
    "dim =len(loaded_data.columns)-1\n",
    "print(f'dim is {dim}')\n",
    "padding_value = 0\n",
    "# Question: Current padding value is 0, is it ok? Do we need it or just resample?\n",
    "data_info = {\n",
    "    'length' : length,\n",
    "    'max_length' : max_len,\n",
    "    'paddding_value_stage' : padding_value,\n",
    "    'dim' : dim\n",
    "}\n",
    "\n",
    "loaded_data['Sleeping_stage'] = loaded_data['Sleeping_stage'].apply(lambda x: np.transpose(x))\n",
    "\n",
    "prep_data = pd.DataFrame(columns=['Sleeping_stage','time'])\n",
    "print(f'Padding data to {max_len} length')\n",
    "\n",
    "#shape: [length, max_len,features] = [length, max_len,1]\n",
    "# init empty array\n",
    "padded_data = np.empty((length,max_len,1))\n",
    "#fill array with padding value\n",
    "padded_data.fill(padding_value)\n",
    "\n",
    "time = []\n",
    "\n",
    "for i in range(length):\n",
    "    #get a row of Sleep stage data\n",
    "    tmp_stage = loaded_data.iloc[i]['Sleeping_stage']\n",
    "    #print tmp_stage type\n",
    "    #print(tmp_stage.shape)\n",
    "\n",
    "    #impute missing values\n",
    "    #tmp_stage = impute_missing_values(tmp_stage)\n",
    "    \n",
    "    #get time data\n",
    "    tmp_time = len(tmp_stage)\n",
    "    #reshape tmp_stage to [tmp_time,1]\n",
    "    tmp_stage = tmp_stage.reshape(tmp_time,1)\n",
    "    # pad data to 'max_seq_len'\n",
    "    if len(tmp_stage) >= max_len:\n",
    "        padded_data[i,:,:] = tmp_stage[:max_len,0:]\n",
    "        time.append(max_len)\n",
    "    else:\n",
    "        padded_data[i,:tmp_time,:] = tmp_stage[:,0:]\n",
    "        time.append(len(tmp_stage))\n",
    "array = dismantle_array(padded_data)\n",
    "array = remake_array(array)\n",
    "print(array)\n",
    "\n",
    "plt.plot(array[0,:,0])\n",
    "plt.plot(padded_data[0,:,0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
