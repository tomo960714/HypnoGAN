{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create useable csv files from NSRR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog,messagebox\n",
    "# local packages:\n",
    "import os\n",
    "\n",
    "# personal packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get folder path\n",
    "root=tk.Tk()\n",
    "root.attributes(\"-topmost\", True) \n",
    "root.withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "\n",
    "folder_path = filedialog.askdirectory(parent=root,title='Please select a directory with the o1 folder')\n",
    "\n",
    "if \"o1\" not in folder_path:\n",
    "    if os.path.exists(folder_path + \"/o1\"):\n",
    "        folder_path = folder_path + \"/o1\"\n",
    "        print(folder_path)\n",
    "    else:\n",
    "        print(\"No o1 folder found\")\n",
    "        raise FileNotFoundError\n",
    "else:\n",
    "    print(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files in folder\n",
    "files = os.listdir(folder_path)\n",
    "print(files)\n",
    "used_cols = [3,4]\n",
    "\n",
    "new_names_df = pd.DataFrame(columns=['File name','Sleeping_stage', 'length', 'additional_info'])\n",
    "\n",
    "\n",
    "for index,file in enumerate(files):\n",
    "    #print(index,file)\n",
    "    \n",
    "    temp_df = pd.read_csv(os.path.join(folder_path,file,'STAGE_E.txt'),skiprows=1 ,usecols=used_cols,delimiter='\\t',names=['time','stage'])\n",
    "\n",
    "    # transform stage to values\n",
    "    mapping= {'w': int(1), 'r': int(2), 'n1': int(3), 'n2': int(4), 'n3': int(5)}\n",
    "    temp_df['value'] = temp_df['stage'].apply(lambda x: x.lower()).map(mapping)\n",
    "    #drop row if value is nan\n",
    "    #'time': temp_df['time'].values.tolist(),\n",
    "    row = {\n",
    "        'File name': file,\n",
    "        \n",
    "        'Sleeping_stage': temp_df['value'].values.tolist(),\n",
    "    }\n",
    "    if temp_df['value'].isna().any().any() == False:\n",
    "        new_names_df.loc[index] = row\n",
    "#add the length of the sleep stage array to the dataframe\n",
    "new_names_df['length'] = new_names_df['Sleeping_stage'].apply(lambda x: len(x))\n",
    "#new_names_df['time'] = new_names_df['time'].apply(lambda x: float(x))\n",
    "#new_names_df['Sleeping stage'] = new_names_df['Sleeping stage'].apply(lambda x: float(x))\n",
    "#add additional info\n",
    "# Unused for now\n",
    "#TODO: add additional info\n",
    "\n",
    "#new_names_df[\"Sleeping stage\"] = new_names_df[\"Sleeping stage\"].apply(lambda x: x.astype(int))\n",
    "#new_names_df[\"time\"] = new_names_df[\"time\"].apply(lambda x: x.astype(float))\n",
    "#check if all files are in the dataframe\n",
    "if len(files) == len(new_names_df):\n",
    "    print(\"All files are in the dataframe\")\n",
    "else:\n",
    "    print(\"Not all files are in the dataframe\")\n",
    "    print(\"files: \",len(files))\n",
    "    print(\"df: \",len(new_names_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change name here if you want to save to a different file\n",
    "save_filename = 'generated_dataset.csv'\n",
    "popup = messagebox.askyesno(parent=root,title=f\"Append to {save_filename}\",message=f\"Do you want to append to existing {save_filename} file?\")\n",
    "print(popup)\n",
    "if popup:\n",
    "    print(f\"Appending to {save_filename}\")\n",
    "    if os.path.exists(save_filename):\n",
    "        print(f\"{save_filename} exists\")\n",
    "        new_names_df.to_csv(save_filename,index=False,mode='a',header=False,decimal='.',sep=';')\n",
    "    else:\n",
    "        print(f\"{save_filename} does not exist\")\n",
    "        print(f\"Creating {save_filename}\")\n",
    "        new_names_df.to_csv(save_filename,index=False,decimal='.',sep=';')\n",
    "else:\n",
    "    print(\"Creating dataset.csv\")\n",
    "    new_names_df.to_csv(save_filename,index=False,sep=';',decimal='.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        Sleeping_stage   \n",
      "File name                                                                \n",
      "abc-baseline-900001  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \\\n",
      "abc-baseline-900002  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "abc-baseline-900003  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "abc-baseline-900004  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "abc-baseline-900005  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "...                                                                ...   \n",
      "shhs2-205786         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
      "shhs2-205796         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "shhs2-205797         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "shhs2-205798         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "shhs2-205800         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "\n",
      "                     length  additional_info  \n",
      "File name                                     \n",
      "abc-baseline-900001    1027              NaN  \n",
      "abc-baseline-900002     985              NaN  \n",
      "abc-baseline-900003    1030              NaN  \n",
      "abc-baseline-900004    1101              NaN  \n",
      "abc-baseline-900005    1016              NaN  \n",
      "...                     ...              ...  \n",
      "shhs2-205786           1260              NaN  \n",
      "shhs2-205796           1140              NaN  \n",
      "shhs2-205797           1379              NaN  \n",
      "shhs2-205798           1350              NaN  \n",
      "shhs2-205800           1320              NaN  \n",
      "\n",
      "[8573 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "file_1 = 'generated_dataset_ABC.csv'\n",
    "file_2 = 'generated_dataset_SHHS.csv'\n",
    "output_file = 'generated_dataset.csv'\n",
    "\n",
    "df_1 = pd.read_csv(file_1,sep=';')\n",
    "df_2 = pd.read_csv(file_2,sep=';')\n",
    "#print(df_1)\n",
    "\n",
    "#merge_df = pd.merge(df_1, df_2)\n",
    "merged_df = pd.concat([df_1, df_2])\n",
    "\n",
    "print(merged_df)\n",
    "\n",
    "#merged_df.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Sleeping_stage  length   \n",
      "File name                                                                 \n",
      "shhs1-200001  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    1084  \\\n",
      "shhs1-200002  [4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, ...    1079   \n",
      "shhs1-200003  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    1049   \n",
      "shhs1-200004  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     875   \n",
      "shhs1-200005  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    1084   \n",
      "\n",
      "              additional_info  \n",
      "File name                      \n",
      "shhs1-200001              NaN  \n",
      "shhs1-200002              NaN  \n",
      "shhs1-200003              NaN  \n",
      "shhs1-200004              NaN  \n",
      "shhs1-200005              NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = \"generated_dataset_SHHS.csv\"\n",
    "dataset = pd.read_csv(filename,sep=';',index_col=0)\n",
    "dataset = dataset.drop('time', axis=0)\n",
    "print(dataset.head())\n",
    "dataset.to_csv(filename,sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac0a6d3b2797ecb631117927a746b20953cdb17b79539a7e8c29303730c81e58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
