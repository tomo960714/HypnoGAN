{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create useable csv files from NSRR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog,messagebox\n",
    "# local packages:\n",
    "import os\n",
    "\n",
    "# personal packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get folder path\n",
    "root=tk.Tk()\n",
    "root.attributes(\"-topmost\", True) \n",
    "root.withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "\n",
    "folder_path = filedialog.askdirectory(parent=root,title='Please select a directory with the o1 folder')\n",
    "\n",
    "if \"o1\" not in folder_path:\n",
    "    if os.path.exists(folder_path + \"/o1\"):\n",
    "        folder_path = folder_path + \"/o1\"\n",
    "        print(folder_path)\n",
    "    else:\n",
    "        print(\"No o1 folder found\")\n",
    "        raise FileNotFoundError\n",
    "else:\n",
    "    print(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files in folder\n",
    "files = os.listdir(folder_path)\n",
    "print(files)\n",
    "used_cols = [3,4]\n",
    "\n",
    "new_names_df = pd.DataFrame(columns=['File name','Sleeping_stage', 'length', 'additional_info'])\n",
    "\n",
    "\n",
    "for index,file in enumerate(files):\n",
    "    #print(index,file)\n",
    "    \n",
    "    temp_df = pd.read_csv(os.path.join(folder_path,file,'STAGE_E.txt'),skiprows=1 ,usecols=used_cols,delimiter='\\t',names=['time','stage'])\n",
    "\n",
    "    # transform stage to values\n",
    "    mapping= {'w': int(1), 'r': int(2), 'n1': int(3), 'n2': int(4), 'n3': int(5)}\n",
    "    temp_df['value'] = temp_df['stage'].apply(lambda x: x.lower()).map(mapping)\n",
    "    #drop row if value is nan\n",
    "    #'time': temp_df['time'].values.tolist(),\n",
    "    row = {\n",
    "        'File name': file,\n",
    "        \n",
    "        'Sleeping_stage': temp_df['value'].values.tolist(),\n",
    "    }\n",
    "    if temp_df['value'].isna().any().any() == False:\n",
    "        new_names_df.loc[index] = row\n",
    "#add the length of the sleep stage array to the dataframe\n",
    "new_names_df['length'] = new_names_df['Sleeping_stage'].apply(lambda x: len(x))\n",
    "#new_names_df['time'] = new_names_df['time'].apply(lambda x: float(x))\n",
    "#new_names_df['Sleeping stage'] = new_names_df['Sleeping stage'].apply(lambda x: float(x))\n",
    "#add additional info\n",
    "# Unused for now\n",
    "#TODO: add additional info\n",
    "\n",
    "#new_names_df[\"Sleeping stage\"] = new_names_df[\"Sleeping stage\"].apply(lambda x: x.astype(int))\n",
    "#new_names_df[\"time\"] = new_names_df[\"time\"].apply(lambda x: x.astype(float))\n",
    "#check if all files are in the dataframe\n",
    "if len(files) == len(new_names_df):\n",
    "    print(\"All files are in the dataframe\")\n",
    "else:\n",
    "    print(\"Not all files are in the dataframe\")\n",
    "    print(\"files: \",len(files))\n",
    "    print(\"df: \",len(new_names_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change name here if you want to save to a different file\n",
    "save_filename = 'generated_dataset.csv'\n",
    "popup = messagebox.askyesno(parent=root,title=f\"Append to {save_filename}\",message=f\"Do you want to append to existing {save_filename} file?\")\n",
    "print(popup)\n",
    "if popup:\n",
    "    print(f\"Appending to {save_filename}\")\n",
    "    if os.path.exists(save_filename):\n",
    "        print(f\"{save_filename} exists\")\n",
    "        new_names_df.to_csv(save_filename,index=False,mode='a',header=False,decimal='.',sep=';')\n",
    "    else:\n",
    "        print(f\"{save_filename} does not exist\")\n",
    "        print(f\"Creating {save_filename}\")\n",
    "        new_names_df.to_csv(save_filename,index=False,decimal='.',sep=';')\n",
    "else:\n",
    "    print(\"Creating dataset.csv\")\n",
    "    new_names_df.to_csv(save_filename,index=False,sep=';',decimal='.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = 'generated_dataset_ABC.csv'\n",
    "file_2 = 'generated_dataset_SHHS.csv'\n",
    "output_file = 'generated_dataset.csv'\n",
    "\n",
    "df_1 = pd.read_csv(file_1)\n",
    "df_2 = pd.read_csv(file_2)\n",
    "\n",
    "merge_df = pd.merge(df_1, df_2,on='common_column')\n",
    "\n",
    "merge_df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac0a6d3b2797ecb631117927a746b20953cdb17b79539a7e8c29303730c81e58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
