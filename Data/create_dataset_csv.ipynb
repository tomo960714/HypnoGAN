{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create useable csv files from NSRR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd party packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog,messagebox\n",
    "# local packages:\n",
    "import os\n",
    "\n",
    "# personal packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/tomo9/Documents/00_School/00_Thesis/HypnoGAN/Data/ABC/o1\n"
     ]
    }
   ],
   "source": [
    "# get folder path\n",
    "root=tk.Tk()\n",
    "root.attributes(\"-topmost\", True) \n",
    "root.withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "\n",
    "folder_path = filedialog.askdirectory(parent=root,title='Please select a directory with the o1 folder')\n",
    "\n",
    "if \"o1\" not in folder_path:\n",
    "    if os.path.exists(folder_path + \"/o1\"):\n",
    "        folder_path = folder_path + \"/o1\"\n",
    "        print(folder_path)\n",
    "    else:\n",
    "        print(\"No o1 folder found\")\n",
    "        raise FileNotFoundError\n",
    "else:\n",
    "    print(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc-baseline-900001', 'abc-baseline-900002', 'abc-baseline-900003', 'abc-baseline-900004', 'abc-baseline-900005', 'abc-baseline-900006', 'abc-baseline-900007', 'abc-baseline-900008', 'abc-baseline-900009', 'abc-baseline-900010', 'abc-baseline-900011', 'abc-baseline-900012', 'abc-baseline-900013', 'abc-baseline-900014', 'abc-baseline-900015', 'abc-baseline-900016', 'abc-baseline-900017', 'abc-baseline-900018', 'abc-baseline-900019', 'abc-baseline-900020', 'abc-baseline-900021', 'abc-baseline-900022', 'abc-baseline-900023', 'abc-baseline-900024', 'abc-baseline-900025', 'abc-baseline-900026', 'abc-baseline-900027', 'abc-baseline-900028', 'abc-baseline-900029', 'abc-baseline-900030', 'abc-baseline-900031', 'abc-baseline-900032', 'abc-baseline-900033', 'abc-baseline-900034', 'abc-baseline-900035', 'abc-baseline-900036', 'abc-baseline-900037', 'abc-baseline-900038', 'abc-baseline-900039', 'abc-baseline-900040', 'abc-baseline-900041', 'abc-baseline-900042', 'abc-baseline-900043', 'abc-baseline-900044', 'abc-baseline-900045', 'abc-baseline-900046', 'abc-baseline-900047', 'abc-baseline-900048', 'abc-baseline-900049', 'abc-month09-900001', 'abc-month09-900002', 'abc-month09-900003', 'abc-month09-900004', 'abc-month09-900005', 'abc-month09-900006', 'abc-month09-900008', 'abc-month09-900009', 'abc-month09-900010', 'abc-month09-900011', 'abc-month09-900012', 'abc-month09-900013', 'abc-month09-900014', 'abc-month09-900015', 'abc-month09-900016', 'abc-month09-900018', 'abc-month09-900019', 'abc-month09-900020', 'abc-month09-900021', 'abc-month09-900022', 'abc-month09-900023', 'abc-month09-900024', 'abc-month09-900025', 'abc-month09-900027', 'abc-month09-900028', 'abc-month09-900029', 'abc-month09-900030', 'abc-month09-900031', 'abc-month09-900032', 'abc-month09-900034', 'abc-month09-900035', 'abc-month09-900036', 'abc-month09-900037', 'abc-month09-900038', 'abc-month09-900039', 'abc-month09-900040', 'abc-month09-900041', 'abc-month09-900042', 'abc-month09-900043', 'abc-month09-900045', 'abc-month09-900046', 'abc-month09-900047', 'abc-month09-900049', 'abc-month18-900001', 'abc-month18-900002', 'abc-month18-900003', 'abc-month18-900004', 'abc-month18-900005', 'abc-month18-900008', 'abc-month18-900009', 'abc-month18-900010', 'abc-month18-900011', 'abc-month18-900012', 'abc-month18-900013', 'abc-month18-900014', 'abc-month18-900015', 'abc-month18-900016', 'abc-month18-900018', 'abc-month18-900019', 'abc-month18-900020', 'abc-month18-900021', 'abc-month18-900022', 'abc-month18-900023', 'abc-month18-900024', 'abc-month18-900025', 'abc-month18-900027', 'abc-month18-900028', 'abc-month18-900030', 'abc-month18-900031', 'abc-month18-900032', 'abc-month18-900034', 'abc-month18-900035', 'abc-month18-900036', 'abc-month18-900037', 'abc-month18-900038', 'abc-month18-900039', 'abc-month18-900040', 'abc-month18-900041', 'abc-month18-900043', 'abc-month18-900045', 'abc-month18-900046', 'abc-month18-900047', 'abc-month18-900049']\n",
      "All files are in the dataframe\n"
     ]
    }
   ],
   "source": [
    "# get all files in folder\n",
    "files = os.listdir(folder_path)\n",
    "print(files)\n",
    "used_cols = [3,4]\n",
    "\n",
    "new_names_df = pd.DataFrame(columns=['File name','time','Sleeping_stage', 'length', 'additional_info'])\n",
    "\n",
    "\n",
    "for index,file in enumerate(files):\n",
    "    #print(index,file)\n",
    "    \n",
    "    temp_df = pd.read_csv(os.path.join(folder_path,file,'STAGE_E.txt'),skiprows=1 ,usecols=used_cols,delimiter='\\t',names=['time','stage'])\n",
    "\n",
    "    # transform stage to values\n",
    "    mapping= {'w': int(1), 'r': int(2), 'n1': int(3), 'n2': int(4), 'n3': int(5)}\n",
    "    temp_df['value'] = temp_df['stage'].apply(lambda x: x.lower()).map(mapping)\n",
    "\n",
    "    row = {\n",
    "        'File name': file,\n",
    "        'time': temp_df['time'].values.tolist(),\n",
    "        'Sleeping_stage': temp_df['value'].values.tolist(),\n",
    "    }\n",
    "    new_names_df.loc[index] = row\n",
    "#add the length of the sleep stage array to the dataframe\n",
    "new_names_df['length'] = new_names_df['Sleeping_stage'].apply(lambda x: len(x))\n",
    "#new_names_df['time'] = new_names_df['time'].apply(lambda x: float(x))\n",
    "#new_names_df['Sleeping stage'] = new_names_df['Sleeping stage'].apply(lambda x: float(x))\n",
    "#add additional info\n",
    "# Unused for now\n",
    "#TODO: add additional info\n",
    "\n",
    "#new_names_df[\"Sleeping stage\"] = new_names_df[\"Sleeping stage\"].apply(lambda x: x.astype(int))\n",
    "#new_names_df[\"time\"] = new_names_df[\"time\"].apply(lambda x: x.astype(float))\n",
    "#check if all files are in the dataframe\n",
    "if len(files) == len(new_names_df):\n",
    "    print(\"All files are in the dataframe\")\n",
    "else:\n",
    "    print(\"Not all files are in the dataframe\")\n",
    "    print(\"files: \",len(files))\n",
    "    print(\"df: \",len(new_names_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Creating dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Change name here if you want to save to a different file\n",
    "save_filename = 'generated_dataset.csv'\n",
    "popup = messagebox.askyesno(parent=root,title=f\"Append to {save_filename}\",message=f\"Do you want to append to existing {save_filename} file?\")\n",
    "print(popup)\n",
    "if popup:\n",
    "    print(f\"Appending to {save_filename}\")\n",
    "    if os.path.exists(save_filename):\n",
    "        print(f\"{save_filename} exists\")\n",
    "        new_names_df.to_csv(save_filename,index=False,mode='a',header=False,decimal='.',sep=';')\n",
    "    else:\n",
    "        print(f\"{save_filename} does not exist\")\n",
    "        print(f\"Creating {save_filename}\")\n",
    "        new_names_df.to_csv(save_filename,index=False,decimal='.',sep=';')\n",
    "else:\n",
    "    print(\"Creating dataset.csv\")\n",
    "    new_names_df.to_csv(save_filename,index=False,sep=';',decimal='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac0a6d3b2797ecb631117927a746b20953cdb17b79539a7e8c29303730c81e58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
